{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: TITAN X (Pascal) (CNMeM is disabled, cuDNN 5110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th theano\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "sys.path.insert(0, '../../MyPackages/')\n",
    "sys.path.insert(0, '../../MyPackages/Inception-v4/')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2, os, random, time\n",
    "from tqdm import tqdm\n",
    "\n",
    "## set global parameters: backend and image_dim_ordering for keras, and the gpu configuration\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano' # or 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "## for tensorflow sesstion\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# config.allow_soft_placement = True\n",
    "# config.log_device_placement = True\n",
    "# sess = tf.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "print K.image_dim_ordering(), K.backend()\n",
    "\n",
    "## import keras layers\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from inception_v4 import create_inception_v4\n",
    "from Package_dataset import Load_AVAdataset\n",
    "from Package_network import loop_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249529, 3, 224, 224) (249529,) (249529,)\n",
      "(3000, 3, 224, 224) (3000,)\n",
      "(3000, 3, 224, 224) (3000,)\n"
     ]
    }
   ],
   "source": [
    "## load the AVA dataset, hdf5 format\n",
    "h5f_AVA = Load_AVAdataset(target_size=(224,224))\n",
    "images_train = h5f_AVA['images_train']\n",
    "scores_train = h5f_AVA['scores_train']\n",
    "scores_train = scores_train[:,0]\n",
    "sample_weights = h5f_AVA['sample_weights_train'][:]\n",
    "\n",
    "images_test_even = h5f_AVA['images_test_even']\n",
    "scores_test_even = h5f_AVA['scores_test_even']\n",
    "scores_test_even = scores_test_even[:,0]\n",
    "images_test_uneven = h5f_AVA['images_test_uneven']\n",
    "scores_test_uneven = h5f_AVA['scores_test_uneven']\n",
    "scores_test_uneven = scores_test_uneven[:,0]\n",
    "\n",
    "print images_train.shape, scores_train.shape, sample_weights.shape\n",
    "print images_test_even.shape, scores_test_even.shape\n",
    "print images_test_uneven.shape, scores_test_uneven.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x, dim_ordering='default'):\n",
    "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: input Numpy tensor, 4D.\n",
    "        dim_ordering: data format of the image tensor.\n",
    "    # Returns\n",
    "        Preprocessed tensor.\n",
    "    \"\"\"\n",
    "    if dim_ordering == 'default':\n",
    "        dim_ordering = K.image_dim_ordering()\n",
    "    assert dim_ordering in {'tf', 'th'}\n",
    "\n",
    "#     x = np.transpose(x,(0,2,3,1))\n",
    "    x = x.astype(np.float32,copy=False)\n",
    "    if dim_ordering == 'th':\n",
    "        # 'RGB'->'BGR'\n",
    "#         x = x[:, ::-1, :, :]\n",
    "        # Zero-center by mean pixel\n",
    "        x[:, 0, :, :] -= 103.939 # blue\n",
    "        x[:, 1, :, :] -= 116.779 # green\n",
    "        x[:, 2, :, :] -= 123.68  # red\n",
    "    else:\n",
    "        # 'RGB'->'BGR'\n",
    "#         x = x[:, :, :, ::-1]\n",
    "        # Zero-center by mean pixel\n",
    "        x[:, :, :, 0] -= 103.939 # blue\n",
    "        x[:, :, :, 1] -= 116.779 # green\n",
    "        x[:, :, :, 2] -= 123.68  # red\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## load the network\n",
    "input_tensor = Input(shape=(3, 224, 224))\n",
    "base_model = ResNet50(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1,init='glorot_uniform')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=input_tensor, output=x)\n",
    "myadam = Adam(lr=0.001)\n",
    "model.compile(optimizer=myadam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.72020721  5.25903606  5.31004381  5.43801641  5.84357548  5.81212139\n",
      "  5.86111116  6.10285711  5.6875      5.06204367]\n",
      "press enter to continue\n",
      "[ 4.64285707  4.34482765  6.75478935  3.88489199  4.15272713  6.5\n",
      "  5.01098919  5.47706413  5.15178585  5.38709688]\n",
      "press enter to continue\n",
      "[ 5.13297892  4.640625    4.5219512   5.63535929  5.48167562  6.05851078\n",
      "  5.28676462  5.60233927  5.23770475  4.61363649]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0c57bf494c06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                                    pre_f=preprocess_input, shuffle=False):\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'press enter to continue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bjin/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         )\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bjin/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    717\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for (images_batch,labels_batch,sample_weights_batch) in loop_batch(images_train,scores_train,sample_weights,batch_size=64,\n",
    "                                                                   pre_f=preprocess_input, shuffle=False):\n",
    "    print labels_batch[0:10]\n",
    "    raw_input('press enter to continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "192/200 [===========================>..] - ETA: 0s - loss: 77.3752 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjin/anaconda2/lib/python2.7/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/200 [======================================] - 9s - loss: 73.2150 - val_loss: 37.1888\n",
      "Epoch 2/4\n",
      "256/200 [======================================] - 17s - loss: 23.1268 - val_loss: 1638.4445\n",
      "Epoch 3/4\n",
      "256/200 [======================================] - 7s - loss: 11.2600 - val_loss: 681.8810\n",
      "Epoch 4/4\n",
      "256/200 [======================================] - 7s - loss: 22.5086 - val_loss: 4308.7133\n"
     ]
    }
   ],
   "source": [
    "# with K.tf.device('/gpu:0'):\n",
    "checkpointer = ModelCheckpoint(filepath=\"/data/bjin/MyAesthetics/model_weights/AVA_Resnet50_score.hdf5\", \n",
    "                                verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=2)\n",
    "# mytensorboard = TensorBoard(log_dir='/data/bjin/MyAesthetics/logs/Resnet', histogram_freq=5, write_graph=True)\n",
    "# history = model.fit(x=images_train,y=scores_train,batch_size=64, nb_epoch=10, verbose=1,callbacks=[checkpointer],\n",
    "#         validation_data=(images_test_even,scores_test_even),shuffle=False,sample_weight=sample_weights)\n",
    "\n",
    "#         validation_data=loop_batch(images_test_even,scores_test_even,batch_size=64,pre_f=preprocess_input),\n",
    "#             nb_val_samples=len(scores_test_even)\n",
    "\n",
    "history = model.fit_generator(loop_batch(images_train,scores_train,sample_weights,batch_size=64,pre_f=preprocess_input),\n",
    "        samples_per_epoch=len(scores_train), nb_epoch=4, callbacks=[checkpointer], verbose=1,\n",
    "        validation_data=loop_batch(images_test_even,scores_test_even,batch_size=64,pre_f=preprocess_input),\n",
    "        nb_val_samples=200, max_q_size=5, nb_worker=1, pickle_safe=False, initial_epoch=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [73.215046405792236,\n",
       "  23.126758575439453,\n",
       "  11.259980082511902,\n",
       "  22.508553743362427],\n",
       " 'val_loss': [37.188783645629883,\n",
       "  1638.4444885253906,\n",
       "  681.88096618652344,\n",
       "  4308.7132568359375]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with K.tf.device('/gpu:0'): \n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                        verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with K.tf.device('/gpu:1'):\n",
    "#     with K.tf.Session(config=config):\n",
    "#     K.set_session(K.tf.Session(config=config))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=RMSprop(),\n",
    "          metrics=['accuracy'])\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size=batch_size, nb_epoch=4,\n",
    "                        verbose=1, validation_data=(X_test, Y_test))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "with K.tf.device('/cpu:0'):\n",
    "    score = score + [1,1]\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with K.tf.device('/cpu:0'):\n",
    "    model_inceptionv4 = create_inception_v4(nb_classes=1001, load_weights=True)\n",
    "    input_tensor = Input(shape=(224, 224, 3))\n",
    "    model = InceptionV4(input_tensor=input_tensor,weights=None, include_top=False)\n",
    "\n",
    "    for idx in range(len(model.layers)):\n",
    "        w = model_inceptionv4.layers[idx].get_weights()\n",
    "        model.layers[idx].set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model.layers)):\n",
    "    w = model_inceptionv4.layers[idx].get_weights()\n",
    "    model.layers[idx].set_weights(w)\n",
    "\n",
    "model.save_weights('/home/bjin/.keras/models/inception_v4_weights_tf_dim_ordering_tf_kernels_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(model_inceptionv4, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
