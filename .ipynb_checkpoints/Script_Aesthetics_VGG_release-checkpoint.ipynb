{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme\n",
    "1. This is the code for predicting aesthetic scores or histograms using the method in the paper:\n",
    "Jin, Bin, Maria V. Ortiz Segovia, and Sabine SÃ¼sstrunk. \"Image aesthetic predictors based on weighted CNNs.\" Image Processing (ICIP), 2016 IEEE International Conference on. IEEE, 2016.\n",
    "\n",
    "2. To use the code, you need to install the following packages:\n",
    "Theano(>=0.9), Keras(>=1.0), numpy, opencv\n",
    "\n",
    "3. To run the code: please download the weights from our project webpage.\n",
    "There are two weights hdf5 files, one is for predicting the aesthetics score (1 value), the other one is for predicting the histogram (10 bins). Both of them are ~500 MB since the network architecture is VGG16.\n",
    "Modify the \"outputflag\" parameter to change between score prediction or histogram prediction. \n",
    "\n",
    "----------Created by Bin Jin. Nov. 16th, 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2, os, random, time\n",
    "\n",
    "## set global parameters: backend and image_dim_ordering for keras, and the gpu configuration\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano' # or 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AestheticNet(outputflag='score',weight_decay=0.0005, weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2))) # The receptive filed is 7*7 here\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu',init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    if outputflag =='score' :\n",
    "        model.add(Dense(1,init='he_normal',W_regularizer=l2(weight_decay)))\n",
    "    else:\n",
    "        model.add(Dense(10, activation='softmax',init='he_normal',W_regularizer=l2(weight_decay)))    \n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the weights of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputflag = 'score' ## 'score' for predicting the aesthetic score (1 value),'hist' for predicting the histogram (10 bins)\n",
    "path_weights = './' ## modify to the path where you put the downloaded weights\n",
    "weights_file = 'AVA_AestheticNet_' + outputflag + '_ICIP.h5'\n",
    "model = AestheticNet(outputflag=outputflag,weight_decay=0.0005, weights_path=path_weights + weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_images = './'\n",
    "filename = 'example.jpg' ## specify your own image\n",
    "\n",
    "img = cv2.imread(path_images + filename)\n",
    "imgn = np.copy(img)\n",
    "imgn = cv2.resize(imgn,(224,224))\n",
    "imgn = np.transpose(imgn,[2,0,1])\n",
    "imgn = np.expand_dims(imgn,axis=0)\n",
    "score = model.predict(imgn)\n",
    "\n",
    "img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print filename + ': ', score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### code for cropping the input image for aesthetic appealingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## function for generating crop:\n",
    "## Inputs:\n",
    "##     ---- img: the input image, the format should be (height, width, 3)\n",
    "##     ---- model: the aesthetics prediction model\n",
    "##     ---- n_crops_attemp: number of random crops to choose from, the more, the slower\n",
    "##     ---- aespect_ratio_h, aespect_ratio_w: the aespect ratio number for the height and width, the generated crop will\n",
    "##                                            be in the aespect ratio of: aespect_ratio_h:aespect_ratio_w (e.g. 16:9)\n",
    "##     ---- length_constrain: constrain the minsize of the crop to be larger than a percentage of the width or height.\n",
    "##\n",
    "## Outputs:\n",
    "##     ---- crop_best: the generated best crop of the input image\n",
    "##     ---- score_best: the aesthetics score of the returned crop, in range (0,1)\n",
    "\n",
    "def generate_crop(img, model, n_crops_attemp=250, aespect_ratio_h=9, aespect_ratio_w=16,length_constrain = 0.5):\n",
    "    \n",
    "    [h,w,c] = img.shape\n",
    "    images_batch = np.zeros((n_crops_attemp,3,224,224),np.float32)\n",
    "    coordinates_batch = np.zeros((n_crops_attemp,4),dtype=np.uint16)\n",
    "    min_sz_step = int(min(h/aespect_ratio_h, w/aespect_ratio_w))\n",
    "    \n",
    "    for crop_counter in range(n_crops_attemp):\n",
    "        temp = random.randint(int(min_sz_step/2),min_sz_step)\n",
    "        h_temp =  temp * aespect_ratio_h\n",
    "        w_temp = temp * aespect_ratio_w\n",
    "        start_h = random.randint(0,h-h_temp)\n",
    "        start_w = random.randint(0,w-w_temp)\n",
    "        end_h = start_h + h_temp\n",
    "        end_w = start_w + w_temp\n",
    "        img_crop = img[start_h:end_h,start_w:end_w,:]\n",
    "        img_crop = cv2.resize(img_crop,(224,224))\n",
    "\n",
    "        images_batch[crop_counter] = img_crop.transpose((1,2,0))\n",
    "        coordinates_batch[crop_counter] = [start_h, start_w, end_h,end_w]\n",
    "\n",
    "    scores_batch = model.predict(preprocess_input(images_batch))[:]\n",
    "    score_batch_bestidx = np.argmax(scores_batch)\n",
    "    [start_h,start_w,end_h,end_w] = coordinates_batch[score_batch_bestidx]\n",
    "    crop_best = img[start_h:end_h,start_w:end_w,:]\n",
    "    score_best = scores_batch[score_batch_bestidx]\n",
    "    return crop_best, score_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_images = './'\n",
    "filename = 'Holiday.jpeg' ## specify your own image\n",
    "\n",
    "img = cv2.imread(path_images + filename)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "[crop_best,score_best] = generate_crop(img, model, n_crops_attemp=100)\n",
    "plt.imshow(cv2.cvtColor(crop_best, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "print score_best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
